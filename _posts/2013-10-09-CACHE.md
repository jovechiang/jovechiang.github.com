---
layout: post
title: Caching Strategies I
tag: caching
categories: system
---

####Background
In current tech world, performance and scaling are 2 main factors when we design a system. Cache is born for performance improvemant but when it meets with scaling requirement, things are getting interesting. In this post and upcoming posts, I will describe couple caching strategies and try to compare them in a distributed environment.

####Strategies
In this section, I will describe 5 types of caching strategies: _cache aside_, _ read through_, _read ahead_, _write through_, _write behind_. 

##### cache aside
This is where application is responsible for reading and writing from the database and the cache doesn't interact with the database at all. The cache is "kept aside" as a faster and more scalable in-memory data store. The application checks the cache before reading anything from the database. And, the application updates the cache after making any updates to the database. This way, the application ensures that the cache is kept synchronized with the database.

##### read through
This is where cache store is responsible for reading from the database. When an application asks the cache for certain key and miss, that will delegate cache store to fetch data from database and populate it in cache for future use. And then return data to application. This performance can be improved by _read ahead_

##### read ahead
This will allow developers to configure a cache to automatically and _asynchronously_ reload any recently accessed cache entry from the cache loader before its expiration. The result is that after a frequently accessed entry has entered the cache, the application will not fell the impact of a read against a potentially slow cache when the entry is reloaded due to expiration. The _asynchronous_ refresh is only triggered when a object that is sufficiently close to its expiration time is accessed. 

##### write through
When the application updates a piece of data in the cache, the operation will not complete/return until the database is also got updated. This does not improve write performance since you are still dealing with the latency of the write to database. Improving write performance is the purpose for the _write behind_.

##### write behind
In this strategy, modified cache entries are asynchronously written to the data source after a configurable delay, whether after 10 seconds, 20 minutes, a day or even a week or longer.For Write-Behind caching, we will maintains a write-behind queue of the data that must be updated in the data source. When the application updates X in the cache, X is added to the write-behind queue (if it isn't there already; otherwise, it is replaced), and after the specified write-behind delay we will call the cache to update the underlying database with the latest state of X. Note that the write-behind delay is relative to the first of a series of modificationsâ€”in other words, the data in the data source will never lag behind the cache by more than the write-behind delay.
